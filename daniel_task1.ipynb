{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Prepare the notebook](#toc1_)    \n",
    "  - [Import necessary libraries](#toc1_1_)    \n",
    "  - [Import the datasets](#toc1_2_)    \n",
    "- [Task 1: Data understanding](#toc2_)    \n",
    "  - [Assessing Data Quality](#toc2_1_)    \n",
    "    - [Verify the datatypes make intuitive sense](#toc2_1_1_)    \n",
    "    - [Check for missing values](#toc2_1_2_)    \n",
    "    - [Check for possible placeholder values](#toc2_1_3_)    \n",
    "    - [Check for duplicates](#toc2_1_4_)    \n",
    "    - [Check for races with more than one road type (cobble, tarmac, gravel)](#toc2_1_5_)    \n",
    "    - [TODO: Check for Inconsistent Values in Categorical Columns?](#toc2_1_6_)    \n",
    "    - [Check Numeric Ranges](#toc2_1_7_)    \n",
    "  - [Data Distribution](#toc2_2_)    \n",
    "    - [Identify outliers using IQR](#toc2_2_1_)    \n",
    "    - [Histograms](#toc2_2_2_)    \n",
    "  - [Relationships between features](#toc2_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Prepare the notebook](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Import necessary libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Import the datasets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_races = pd.read_csv('dataset/races.csv')\n",
    "df_cyclists = pd.read_csv('dataset/cyclists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Task 1: Data understanding](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Assessing Data Quality](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_1_'></a>[Verify the datatypes make intuitive sense](#toc0_)\n",
    "\n",
    "We'll start by making sure the datatypes make intuitive sense with the data we're seeing. This allows us to catch obvious logical mistakes, such as a numeric value (e.g height or weight) stored as a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_races.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The datatypes seem to make sense for these columns. This is my understanding of what each column represents:\n",
    "\n",
    "| Column               | Description                                                                                     | Data Type    |\n",
    "|----------------------|-------------------------------------------------------------------------------------------------|--------------|\n",
    "| _url                 | The URL of the stage.                                                                           | object       |\n",
    "| name                 | The name of the event or race.                                                                  | object       |\n",
    "| points               | Points awarded to cyclists for the... stage?                                                    | float64      |\n",
    "| uci_points           | UCI points awarded for the... stage?                                                            | float64      |\n",
    "| length               | The total length the race stage in meters.                                                      | float64      |\n",
    "| climb_total          | The total elevation climbed in the stage in meters.                                             | float64      |\n",
    "| profile              | The terrain profile of the stage? Seems encoded in some magic numeric value                     | float64      |\n",
    "| startlist_quality    | A numeric value representing the quality of the riders at the start of the stage                | float64      |\n",
    "| average_temperature  | The average temperature during the stage.                                                       | float64      |\n",
    "| date                 | The date and time when the race stage occurred.                                                 | object       |\n",
    "| position             | The final position of the cyclist in the race stage.                                            | int64        |\n",
    "| cyclist              | The name of the cyclist competing in the race stage.                                            | object       |\n",
    "| cyclist_age          | The age of the cyclist at the time of the race stage.                                           | float64      |\n",
    "| is_tarmac            | True if race was on tarmac.                                                                     | bool         |\n",
    "| is_cobbled           | True if race was on cobblestone.                                                                | bool         |\n",
    "| is_gravel            | True if race was on gravel.                                                                     | bool         |\n",
    "| cyclist_team         | The name of the cyclist's team.                                                                 | object       |\n",
    "| delta                | Time difference between the cyclist and the winner of the stage, in seconds.                    | float64      |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclists.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Column       | Description                                                      | Data Type |\n",
    "|--------------|------------------------------------------------------------------|-----------|\n",
    "| _url         | The URL or of the cyclist                                        | object    |\n",
    "| name         | The full name of the cyclist.                                    | object    |\n",
    "| birth_year   | The birth year of the cyclist.                                   | float64   |\n",
    "| weight       | The weight of the cyclist in kilograms.                          | float64   |\n",
    "| height       | The height of the cyclist in meters.                             | float64   |\n",
    "| nationality  | The nationality of the cyclist.                                  | object    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_races.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclists.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_2_'></a>[Check for missing values](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = df_races.isna().sum()\n",
    "\n",
    "# Display the result\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in each column\n",
    "missing_values = df_cyclists.isna().sum()\n",
    "\n",
    "# Display the result\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_3_'></a>[Check for possible placeholder values](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of potential \"placeholders\"\n",
    "unknown_values = [\"unknown\", \"N/A\", \"none\", \"missing\", \"na\", \"null\", \"\", \"other\"]\n",
    "\n",
    "# Check each column for occurrences of these values (case-insensitive)\n",
    "unknown_counts = df_races.apply(lambda col: col.astype(str).str.lower().isin(unknown_values).sum())\n",
    "\n",
    "# Display the counts of \"placeholder\" values for each column\n",
    "print(unknown_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_4_'></a>[Check for duplicates](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find duplicate rows\n",
    "duplicate_rows = df_races[df_races.duplicated()]\n",
    "\n",
    "# Count the number of duplicate rows\n",
    "num_duplicate_rows = duplicate_rows.shape[0]\n",
    "\n",
    "# Display the number of duplicate rows (and the rows themselves if count > 0)\n",
    "print(f\"Number of duplicate rows: {num_duplicate_rows}\")\n",
    "if num_duplicate_rows:\n",
    "    print(\"Duplicate rows:\")\n",
    "    print(duplicate_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_5_'></a>[Check for races with more than one road type (cobble, tarmac, gravel)](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking if more than one road type is True for any record (we don't expect this to happen)\n",
    "multiple_road_types = df_races[(df_races['is_tarmac'] & df_races['is_cobbled']) | \n",
    "                         (df_races['is_tarmac'] & df_races['is_gravel']) | \n",
    "                         (df_races['is_cobbled'] & df_races['is_gravel']) | \n",
    "                         (df_races['is_tarmac'] & df_races['is_gravel'] & df_races['is_cobbled'])]\n",
    "\n",
    "print(multiple_road_types)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_6_'></a>[TODO: Check for Inconsistent Values in Categorical Columns?](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_1_7_'></a>[Check Numeric Ranges](#toc0_)\n",
    "\n",
    "Make sure numeric values fall within realistic ranges (e.g. length cannot be negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_lengths = df_races[df_races['length'] <= 0]\n",
    "print(f\"Number of races with negative or zero length: {len(negative_lengths)}\")\n",
    "\n",
    "negative_climbs = df_races[df_races['climb_total'] <= 0]\n",
    "print(f\"Number of races with negative or zero climb total: {len(negative_climbs)}\")\n",
    "\n",
    "negative_points = df_races[(df_races['points'] < 0) | (df_races['uci_points'] < 0)]\n",
    "print(f\"Number of races with negative points: {len(negative_points)}\")\n",
    "\n",
    "negative_positions = df_races[df_races['position'] < 0]\n",
    "print(f\"Number of races with negative positions: {len(negative_positions)}\")\n",
    "\n",
    "negative_delta = df_races[df_races['delta'] < 0]\n",
    "print(f\"Number of races with negative delta times: {len(negative_delta)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_weights = df_cyclists[df_cyclists['weight'] <= 0]\n",
    "print(f\"Number of cyclists with negative or zero weight: {len(negative_weights)}\")\n",
    "\n",
    "negative_heights = df_cyclists[df_cyclists['height'] <= 0]\n",
    "print(f\"Number of races with negative or zero height: {len(negative_heights)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Data Distribution](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_1_'></a>[Identify outliers using IQR](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iqr(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "    # Use the IQR to find outliers for the column\n",
    "    Q1 = df[column_name].quantile(0.25)\n",
    "    Q3 = df[column_name].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column_name] < lower_bound) | (df[column_name] > upper_bound)]\n",
    "\n",
    "    print(f\"Number of outliers: {len(outliers)}\")\n",
    "\n",
    "    # Plot the data using a boxplot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.boxplot(x=df[column_name])\n",
    "    plt.title(f'Boxplot of Average {column_name} with IQR Outlier Detection')\n",
    "    plt.xlabel(f'Value for column {column_name}')\n",
    "    plt.show()\n",
    "\n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc2_2_2_'></a>[Histograms](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclist heights\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(df_cyclists['height'].dropna(), kde=False, bins=50, color='blue')\n",
    "\n",
    "plt.title('Distribution of heights of cyclists', fontsize=16)\n",
    "plt.xlabel('Height', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclist weights\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(df_cyclists['weight'].dropna(), kde=False, bins=50, color='blue')\n",
    "\n",
    "plt.title('Distribution of weight of cyclists', fontsize=16)\n",
    "plt.xlabel('Height', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_3_'></a>[Relationships between features](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll determine how closely two columns are related by calculating their Pearson correlation coefficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the numeric and boolean columns (as Pearson correlation only works on numerical data)\n",
    "df_numeric = df_races.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# List to hold the results\n",
    "correlations = []\n",
    "\n",
    "# Loop through all possible pairs of columns\n",
    "for col1 in df_numeric.columns:\n",
    "    for col2 in df_numeric.columns:\n",
    "        # Don't correlation a column with itself\n",
    "        if col1 != col2:\n",
    "            # To make sure we only calculate correlation for one ordering of the pair, we'll only\n",
    "            # calculate the pairs where col1 is 'smaller' than col2, ie. when col1 is before col2 in alphabetical order\n",
    "            if col1 < col2:\n",
    "                corr_value = df_numeric[col1].corr(df_numeric[col2], method='pearson')\n",
    "                correlations.append((col1, col2, corr_value))\n",
    "\n",
    "corr_df = pd.DataFrame(correlations, columns=['Feature_1', 'Feature_2', 'Correlation'])\n",
    "\n",
    "# Sort by the ABSOLUTE value of the correlation coefficient (highest first)\n",
    "corr_df['Abs_Correlation'] = corr_df['Correlation'].abs()\n",
    "sorted_corr_df = corr_df.sort_values(by='Abs_Correlation', ascending=False)\n",
    "\n",
    "# Show top 10 pairs with the highest correlations\n",
    "print(sorted_corr_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the numeric and boolean columns (as Pearson correlation only works on numerical data)\n",
    "df_numeric = df_cyclists.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# List to hold the results\n",
    "correlations = []\n",
    "\n",
    "# Loop through all possible pairs of columns\n",
    "for col1 in df_numeric.columns:\n",
    "    for col2 in df_numeric.columns:\n",
    "        # Don't correlation a column with itself\n",
    "        if col1 != col2:\n",
    "            # To make sure we only calculate correlation for one ordering of the pair, we'll only\n",
    "            # calculate the pairs where col1 is 'smaller' than col2, ie. when col1 is before col2 in alphabetical order\n",
    "            if col1 < col2:\n",
    "                corr_value = df_numeric[col1].corr(df_numeric[col2], method='pearson')\n",
    "                correlations.append((col1, col2, corr_value))\n",
    "\n",
    "corr_df = pd.DataFrame(correlations, columns=['Feature_1', 'Feature_2', 'Correlation'])\n",
    "\n",
    "# Sort by the ABSOLUTE value of the correlation coefficient (highest first)\n",
    "corr_df['Abs_Correlation'] = corr_df['Correlation'].abs()\n",
    "sorted_corr_df = corr_df.sort_values(by='Abs_Correlation', ascending=False)\n",
    "\n",
    "# Show top 10 pairs with the highest correlations\n",
    "print(sorted_corr_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "# List to hold the ANOVA results\n",
    "anova_results = []\n",
    "\n",
    "# Loop through the numerical columns (height and weight) and test them against nationality\n",
    "for col in ['height', 'weight']:\n",
    "    # Drop rows with missing values in the numerical column\n",
    "    df_non_missing = df_cyclists.dropna(subset=[col])\n",
    "    \n",
    "    # Group data by nationality and perform ANOVA\n",
    "    grouped_data = [group[col].dropna() for name, group in df_non_missing.groupby('nationality')]\n",
    "    \n",
    "    # Perform ANOVA only if there are at least two groups with data\n",
    "    if len(grouped_data) > 1:\n",
    "        f_stat, p_value = f_oneway(*grouped_data)\n",
    "        anova_results.append(('nationality', col, f_stat, p_value))\n",
    "    else:\n",
    "        anova_results.append(('nationality', col, float('NaN'), float('NaN')))\n",
    "\n",
    "# Convert results to DataFrame\n",
    "anova_df = pd.DataFrame(anova_results, columns=['Categorical_Feature', 'Numeric_Feature', 'F-Statistic', 'p-value'])\n",
    "\n",
    "# Show results sorted by F-statistic\n",
    "print(anova_df.sort_values(by='F-Statistic', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'nationality' and calculate the average weight\n",
    "avg_weight_by_country = df_cyclists.groupby('nationality')['weight'].mean().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "avg_weight_by_country.columns = ['Nationality', 'Average_Weight']\n",
    "avg_weight_by_country_sorted = avg_weight_by_country.sort_values(by='Average_Weight', ascending=True)\n",
    "\n",
    "\n",
    "# Display the result\n",
    "print(avg_weight_by_country_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by 'nationality' and calculate the average weight\n",
    "avg_weight_by_country = df_cyclists.groupby('nationality')['height'].mean().reset_index()\n",
    "\n",
    "# Rename the columns for clarity\n",
    "avg_weight_by_country.columns = ['Nationality', 'Average_Height']\n",
    "avg_weight_by_country_sorted = avg_weight_by_country.sort_values(by='Average_Height', ascending=True)\n",
    "\n",
    "\n",
    "# Display the result\n",
    "print(avg_weight_by_country_sorted)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
