{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Prepare the notebook](#toc1_)    \n",
    "  - [Import necessary libraries](#toc1_1_)    \n",
    "  - [Import the datasets](#toc1_2_)    \n",
    "- [Task 2: Data Transformation](#toc2_)    \n",
    "  - [Feature engineering and/or novel feature definition](#toc2_1_)    \n",
    "  - [Outlier detection](#toc2_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Prepare the notebook](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Import necessary libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Import the datasets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_races = pd.read_csv('dataset/races.csv')\n",
    "df_cyclists = pd.read_csv('dataset/cyclists.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Task 2: Data Transformation](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_1_'></a>[Feature engineering and/or novel feature definition](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = df_cyclists.copy()\n",
    "\n",
    "# Identify rows with missing values\n",
    "missing_before = df_imputed[df_imputed[['weight', 'height']].isnull().any(axis=1)]\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "df_imputed[['weight', 'height']] = imputer.fit_transform(df_imputed[['weight', 'height']])\n",
    "\n",
    "# Identify rows that had missing values before but are now imputed\n",
    "imputed_rows = df_imputed.loc[missing_before.index]\n",
    "\n",
    "# Display (only) the imputed rows\n",
    "print(imputed_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed = df_cyclists.copy()\n",
    "\n",
    "columns_to_impute = ['weight', 'height']\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "df_imputed[columns_to_impute] = imputer.fit_transform(df_imputed[columns_to_impute])\n",
    "\n",
    "# Identify rows with missing values\n",
    "missing_before = df_cyclists[df_cyclists[columns_to_impute].isnull().any(axis=1)]\n",
    "imputed_rows = df_imputed.loc[missing_before.index]\n",
    "\n",
    "# Display the imputed rows from the new dataframe\n",
    "print(\"Imputed Rows:\\n\", imputed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe we can try KNNImputer while including the birthyear and encoding the country as a number?\n",
    "# one-hot encoding makes sense for the nationality to avoid ordinal relationships between countries.\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df_imputed = df_cyclists.copy()\n",
    "\n",
    "# 1. One-Hot Encode 'nationality' to include it in the imputation process\n",
    "encoder = OneHotEncoder(sparse=False, drop='first')  # Drop first to avoid multicollinearity\n",
    "nationality_encoded = encoder.fit_transform(df_cyclists[['nationality']])\n",
    "nationality_encoded_df = pd.DataFrame(nationality_encoded, columns=encoder.get_feature_names_out(['nationality']))\n",
    "\n",
    "pd.set_option('display.max_columns', 100) \n",
    "pd.set_option('display.max_rows', 100)\n",
    "# print(nationality_encoded_df.iloc[0])\n",
    "\n",
    "df_impute_data = pd.concat([df_cyclists[['birth_year', 'weight', 'height']], nationality_encoded_df], axis=1)\n",
    "\n",
    "# Initialize KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=10)\n",
    "\n",
    "# Perform the imputation\n",
    "df_imputed_values = pd.DataFrame(imputer.fit_transform(df_impute_data), columns=df_impute_data.columns)\n",
    "\n",
    "# Replace the imputed weight and height back into the original DataFrame copy\n",
    "df_final = df_cyclists.copy()\n",
    "df_final[['weight', 'height']] = df_imputed_values[['weight', 'height']]\n",
    "\n",
    "# Identify the rows that had missing values before the imputation\n",
    "columns_to_impute = ['weight', 'height']\n",
    "missing_before = df_cyclists[df_cyclists[columns_to_impute].isnull().any(axis=1)]\n",
    "\n",
    "# Display the imputed rows with the full cyclist information\n",
    "imputed_rows = df_final.loc[missing_before.index]\n",
    "\n",
    "# Display the imputed rows (with full cyclist information)\n",
    "print(\"Imputed Rows:\\n\", imputed_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_imputed = df_cyclists.copy()\n",
    "\n",
    "columns_to_impute = ['birth_year']\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=3)\n",
    "\n",
    "df_imputed[columns_to_impute] = imputer.fit_transform(df_imputed[columns_to_impute])\n",
    "\n",
    "# Identify rows with missing values\n",
    "missing_before = df_cyclists[df_cyclists[columns_to_impute].isnull().any(axis=1)]\n",
    "imputed_rows = df_imputed.loc[missing_before.index]\n",
    "\n",
    "# Display the imputed rows from the new dataframe\n",
    "print(\"Imputed Rows:\\n\", imputed_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc2_2_'></a>[Outlier detection](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outliers = iqr(df_races, \"average_temperature\")\n",
    "\n",
    "outliers = iqr(df_races, 'length')\n",
    "\n",
    "# Print the first 10 outliers since we actually HAVE outliers here...\n",
    "print(outliers.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
