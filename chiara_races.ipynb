{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importazione librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "from datasets import load_dataset\n",
    "import numpy\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "dataset_races = load_dataset('csv', data_files='dataset/races.csv')\n",
    "\n",
    "df_races = dataset_races['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of races dataset\n",
    "df_races.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info races dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclists dataset type columns\n",
    "df_races.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclists dataset info\n",
    "df_races.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclists dataset statistic description (numerical columns)\n",
    "df_races.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cyclists dataset statistic description (categorical columns)\n",
    "df_races.describe(include='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the dataset\n",
    "df_races.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique values in each column\n",
    "df_races.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of values in each column\n",
    "df_races.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each categorical column, the number of times each unique value appears in the column\n",
    "for col in df_races.select_dtypes(include='object').columns:\n",
    "    print(df_races[col].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each numerical column, the number of times each unique value appears in the column\n",
    "for col in df_races.select_dtypes(include='number').columns:\n",
    "    print(df_races[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter out duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract duplicate rows\n",
    "dups = df_races.duplicated()\n",
    "\n",
    "# Number of duplicate rows\n",
    "dups.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract duplicate rows\n",
    "dup_df = df_races[df_races.duplicated(keep=False)]\n",
    "\n",
    "# Display duplicate rows\n",
    "dup_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop duplicate rows\n",
    "df_cyclists = df_races.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "df_races.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract rows with missing values\n",
    "df_races[df_cyclists.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sturges rule for approximately Normal distributions\n",
    "def sturges_bin_count(df_cyclists):\n",
    "    \"\"\"Calculate optimal number of bins based on Sturges' rule\"\"\"\n",
    "    return int(np.ceil(np.log2(len(df_cyclists)) + 1))\n",
    "# Freedman-Diaconis Rule is better for data with outliers and skewed distributions\n",
    "def freedman_diaconis_bin_count(data):\n",
    "    \"\"\"Calculate optimal number of bins based on Freedman-Diaconis rule\"\"\"\n",
    "    iqr = np.percentile(data, 75) - np.percentile(data, 25)\n",
    "    bin_width = 2 * iqr * len(data) ** (-1/3)\n",
    "    return int(np.ceil((data.max() - data.min()) / bin_width))\n",
    "\n",
    "#bins_1 = sturges_bin_count(df_cyclists[\"birth_year\"].dropna())\n",
    "#bins_2 = freedman_diaconis_bin_count(df_cyclists[\"birth_year\"].dropna())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclists.isnull().sum() # check for missing values, sum them up by column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations and distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "\n",
    "import pandas\n",
    "\n",
    "\n",
    "def correlations(dataset: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    correlations_dictionary = {\n",
    "        correlation_type: dataset.corr(numeric_only=True, method=correlation_type)\n",
    "        for correlation_type in (\"kendall\", \"pearson\", \"spearman\")\n",
    "    }\n",
    "    for i, k in enumerate(correlations_dictionary.keys()):\n",
    "        correlations_dictionary[k].loc[:, \"correlation_type\"] = k\n",
    "    correlations_matrix = pandas.concat(correlations_dictionary.values())\n",
    "\n",
    "    return correlations_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, Dict, Any\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas\n",
    "\n",
    "\n",
    "def __transform_single_features(dataset: pandas.DataFrame, transformation: str) -> Tuple[\n",
    "    pandas.DataFrame, Dict[str, Any]]:\n",
    "    match transformation:\n",
    "        case \"standard\":\n",
    "            transformed_dataset = dataset.copy().select_dtypes(exclude=[\"object\", \"category\", \"bool\", \"datetime64\"])\n",
    "            transformations = dict()\n",
    "\n",
    "            for feature in transformed_dataset.columns:\n",
    "                transformations[feature] = StandardScaler()\n",
    "                transformed_feature = transformations[feature].fit_transform(transformed_dataset[[feature]]).squeeze()\n",
    "                transformed_dataset = transformed_dataset.astype({feature: transformed_feature.dtype})\n",
    "                transformed_dataset.loc[:, feature] = transformed_feature\n",
    "        case _:\n",
    "            raise ValueError(f\"Unknown transformation: {transformation}\")\n",
    "\n",
    "    return transformed_dataset, transformations\n",
    "\n",
    "def center_and_scale(dataset: pandas.DataFrame) -> Tuple[pandas.DataFrame, Dict[str, Any]]:\n",
    "    \"\"\"Shifts data to the origin: removes mean and scales by standard deviation all numeric features. Returns a copy of the dataset.\"\"\"\n",
    "    return __transform_single_features(dataset, \"standard\")\n",
    "\n",
    "\n",
    "def drop_boolean(dataset: pandas.DataFrame) -> pandas.DataFrame:\n",
    "    return dataset.select_dtypes(exclude=\"bool\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_dataset, normalization_scalers_dataset = center_and_scale(df_races) # center and scale the dataset\n",
    "\n",
    "correlations = correlations(normalized_dataset) # calculate the correlations between the columns\n",
    "correlations # show the correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#seaborn.pairplot(df_races) # create a pairplot of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_races.select_dtypes(include=\"number\").columns: \n",
    "    seaborn.displot(df_races, x=feature) # create a histogram of each numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.boxenplot(normalized_dataset, orient=\"h\") # create a boxen plot of the normalized dataset\n",
    "normalized_dataset.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = seaborn.catplot(normalized_dataset, kind=\"box\") # create a box plot of the normalized dataset\n",
    "g.set_xticklabels(rotation=90) # rotate the x-axis labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
