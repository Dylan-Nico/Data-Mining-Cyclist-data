{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Prepare the notebook](#toc1_)    \n",
    "  - [Import necessary libraries](#toc1_1_)    \n",
    "  - [Import the datasets](#toc1_2_)    \n",
    "- [PCA](#toc2_)    \n",
    "- [Distributional approach](#toc3_)    \n",
    "- [Connectivity approach](#toc4_)    \n",
    "- [One-class SVM](#toc5_)    \n",
    "- [Isolation forest](#toc6_)    \n",
    "- [Get the final list of 'outlier' columns](#toc7_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Prepare the notebook](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Import necessary libraries](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install numpy\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install outlier_utils\n",
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Import the datasets](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will load the dataset with the already imputed values. This prevents us from having to ignore a ton of rows (since the outlier detection tests cannot run if there are missing values, we would need to drop the rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_races = pd.read_csv('../dataset/df_races_no_missing.csv')\n",
    "df_cyclists = pd.read_csv('../dataset/df_cyclists_no_missing.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100) \n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[PCA](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "pd.set_option('display.expand_frame_repr', False)  # Prevent wrapping to multiple lines because it's difficult to read\n",
    "\n",
    "def pca_outlier_contribution_and_plot_3d(df, columns, n_components=3, threshold=2.5):\n",
    "    \"\"\"\n",
    "    Perform PCA-based outlier detection and return a DataFrame with outlier information.\n",
    "    \n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        columns (list): A list of column names to apply PCA outlier detection.\n",
    "        n_components (int): Number of principal components to use (default: 3).\n",
    "        threshold (float): The reconstruction error threshold for identifying outliers (default: 2.5).\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Modified DataFrame with reconstruction error and outlier flag.\n",
    "    \"\"\"\n",
    "    # Ensure only the specified columns are selected\n",
    "    df_numerical = df[columns]\n",
    "    \n",
    "    # Drop rows with missing values (NaN) in the selected columns. There shouldn't be any since this set\n",
    "    # of tests runs after the imputations, but we'll keep this in case we want to run it before imputing missing values.\n",
    "    df_numerical_cleaned = df_numerical.dropna()\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_numerical_cleaned)\n",
    "    \n",
    "    # Apply the PCA to reduce the dimensionality of the numerical data to the desired number of components\n",
    "    pca = PCA(n_components=n_components)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "    X_reconstructed = pca.inverse_transform(X_pca)\n",
    "    \n",
    "    # Calculate the reconstruction error, and flag each component with an error higher than the threshold\n",
    "    column_wise_error = (X_scaled - X_reconstructed) ** 2\n",
    "    reconstruction_error = np.sum(column_wise_error, axis=1)\n",
    "    outliers = reconstruction_error > threshold\n",
    "    \n",
    "    df_copy = df.loc[df_numerical_cleaned.index].copy()\n",
    "    df_copy['reconstruction_error'] = reconstruction_error\n",
    "    df_copy['pca_outlier'] = outliers\n",
    "    \n",
    "    # Compute and show the PCA loadings\n",
    "    # This tells us which columns \"contribute\" the most to each dimension in our PCA space\n",
    "    loadings = pd.DataFrame(pca.components_.T, columns=[f'PC{i+1}' for i in range(n_components)], index=columns)\n",
    "    print(\"PCA Loadings (weights of each feature on the principal components):\")\n",
    "    print(loadings)\n",
    "    \n",
    "    # Next create a 3d plot to visualize our components\n",
    "    fig = px.scatter_3d(\n",
    "        x=X_pca[:, 0],\n",
    "        y=X_pca[:, 1],\n",
    "        z=X_pca[:, 2],\n",
    "        title='3D PCA Manifold with Outliers',\n",
    "        labels={'x': 'PC1', 'y': 'PC2', 'z': 'PC3'},\n",
    "        opacity=0.7,\n",
    "    )\n",
    "    \n",
    "    fig.update_traces(marker=dict(size=5))\n",
    "    fig.show()\n",
    "    \n",
    "    # If a row is an outlier, find which columns contributed most to the error\n",
    "    # (useful to understand why a record is identified as an outlier)\n",
    "    contribution = pd.DataFrame(column_wise_error, columns=df_numerical_cleaned.columns, index=df_numerical_cleaned.index)\n",
    "\n",
    "    return df_copy, contribution, loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Races DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the columns we care about for the PCA\n",
    "selected_columns = ['points', 'uci_points', 'length', 'climb_total', 'profile', 'startlist_quality', 'cyclist_age']\n",
    "df_races_with_outliers, contribution_df, loadings_df = pca_outlier_contribution_and_plot_3d(df_races, selected_columns, n_components=3, threshold=15)\n",
    "\n",
    "print(df_races_with_outliers[df_races_with_outliers['pca_outlier']])\n",
    "\n",
    "outliers_contributions = contribution_df.loc[df_races_with_outliers[df_races_with_outliers['pca_outlier']].index]\n",
    "print(outliers_contributions)\n",
    "\n",
    "print(loadings_df)\n",
    "\n",
    "# Drop the reconstruction_error column since we don't want it from now on\n",
    "df_races_with_outliers.drop('reconstruction_error', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclist DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all the columns we care about for the PCA\n",
    "selected_columns = ['birth_year', 'weight', 'height'] \n",
    "df_cyclists_with_outliers, contribution_df, loadings_df = pca_outlier_contribution_and_plot_3d(df_cyclists, selected_columns, n_components=3, threshold=15)\n",
    "\n",
    "print(df_cyclists_with_outliers[df_cyclists_with_outliers['pca_outlier']])\n",
    "\n",
    "outliers_contributions = contribution_df.loc[df_cyclists_with_outliers[df_cyclists_with_outliers['pca_outlier']].index]\n",
    "print(outliers_contributions)\n",
    "\n",
    "print(loadings_df)\n",
    "\n",
    "# Drop the reconstruction_error column since we don't want it from now on\n",
    "df_cyclists_with_outliers.drop('reconstruction_error', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Distributional approach](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gmm_test(df):\n",
    "    \"\"\"\n",
    "    Apply a Gaussian Mixture Model (GMM) to detect outliers in a DataFrame.\n",
    "\n",
    "    This function identifies potential outliers in the numeric columns of a DataFrame using a Gaussian Mixture Model.\n",
    "    Rows that fall below a specified threshold in terms of density degree are marked as outliers.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A DataFrame containing the data to be analyzed. Only numeric columns are considered for outlier detection.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with additional columns, density_degree and gmm_outlier\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If there are no numeric columns in the DataFrame.\n",
    "    \"\"\"\n",
    "    # Select only numeric columns from df\n",
    "    numeric_columns = df.select_dtypes(include=\"number\")\n",
    "    # Drop rows with missing values (NaN) in the selected columns. There shouldn't be any since this set\n",
    "    # of tests runs after the imputations, but we'll keep this in case we want to run it before imputing missing values.\n",
    "    numeric_data = numeric_columns.dropna()\n",
    "\n",
    "    k = 5\n",
    "    algorithm = GaussianMixture(n_components=k, random_state=42)\n",
    "    algorithm.fit(numeric_data.values)\n",
    "\n",
    "    outlier_degrees_per_normal = algorithm.predict_proba(numeric_data.values)\n",
    "    outlier_degrees = outlier_degrees_per_normal.max(axis=1)  # Higher values indicate more normal, lower values more likely outlier\n",
    "\n",
    "    outlier_scores_df = pd.DataFrame(outlier_degrees, index=numeric_data.index, columns=[\"density_degree\"])\n",
    "\n",
    "    # Define threshold (e.g., below the 5th percentile could be outliers)\n",
    "    threshold = outlier_scores_df[\"density_degree\"].quantile(0.05)\n",
    "    outlier_series = pd.Series(False, index=df.index)\n",
    "    outlier_series[numeric_data.index] = outlier_scores_df[\"density_degree\"] < threshold\n",
    "\n",
    "    # Merge the outlier degree and boolean outlier column back into the original DataFrame\n",
    "    df[\"density_degree\"] = outlier_scores_df[\"density_degree\"]\n",
    "    df[\"gmm_outlier\"] = outlier_series\n",
    "\n",
    "    # Sort the DataFrame by \"density_degree\" in ascending order. This is useful for manual reviewing\n",
    "    df_sorted = df.sort_values(by=\"density_degree\", ascending=True)\n",
    "\n",
    "    # Plot the result\n",
    "    sorted_outlier_degrees = sorted(outlier_degrees)\n",
    "    sns.lineplot(\n",
    "        x=range(len(sorted_outlier_degrees)),\n",
    "        y=sorted_outlier_degrees\n",
    "    )\n",
    "\n",
    "    return df_sorted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_races_with_outliers = gmm_test(df_races_with_outliers)\n",
    "\n",
    "outlier_rows = df_races_with_outliers[df_races_with_outliers[\"gmm_outlier\"] == True]\n",
    "print(outlier_rows)\n",
    "\n",
    "# Drop the density degree column since we don't want it from now on\n",
    "df_races_with_outliers.drop('density_degree', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclists_with_outliers = gmm_test(df_cyclists_with_outliers)\n",
    "\n",
    "outlier_rows = df_cyclists_with_outliers[df_cyclists_with_outliers[\"gmm_outlier\"] == True]\n",
    "print(outlier_rows)\n",
    "\n",
    "# Drop the density degree column since we don't want it from now on\n",
    "df_cyclists_with_outliers.drop('density_degree', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Connectivity approach](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectivity_approach(df):\n",
    "    \"\"\"\n",
    "    Detect outliers in a DataFrame using the Local Outlier Factor (LOF) connectivity-based approach.\n",
    "\n",
    "    This function applies the Local Outlier Factor (LOF) algorithm to identify outliers in the numeric columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A DataFrame containing the data to be analyzed. Only numeric columns are considered for outlier detection.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with an additional column, \"connectivity_approach_outlier\".\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If there are no numeric columns in the DataFrame.\n",
    "    \"\"\"\n",
    "    import seaborn as sns\n",
    "    from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "    # Select only numeric columns from df\n",
    "    numeric_columns = df.select_dtypes(include=\"number\")\n",
    "    # Drop rows with missing values (NaN) in the selected columns. There shouldn't be any since this set\n",
    "    # of tests runs after the imputations, but we'll keep this in case we want to run it before imputing missing values.\n",
    "    numeric_data = numeric_columns.dropna()\n",
    "\n",
    "    k = 25\n",
    "    algorithm = LocalOutlierFactor(n_neighbors=k)\n",
    "\n",
    "    outlier_predictions = algorithm.fit_predict(numeric_data)\n",
    "\n",
    "    outlier_series = pd.Series(False, index=df.index)\n",
    "\n",
    "    outlier_series[numeric_data.index] = (outlier_predictions == -1)\n",
    "\n",
    "    df[\"connectivity_approach_outlier\"] = outlier_series\n",
    "\n",
    "    outlier_degrees = -algorithm.negative_outlier_factor_\n",
    "    sorted_outlier_degrees = sorted(outlier_degrees)\n",
    "\n",
    "    # Plot the result\n",
    "    sns.lineplot(\n",
    "        x=range(len(sorted_outlier_degrees)),\n",
    "        y=sorted_outlier_degrees\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_races_with_outliers = connectivity_approach(df_races_with_outliers)\n",
    "\n",
    "outlier_rows = df_races_with_outliers[df_races_with_outliers[\"connectivity_approach_outlier\"] == True]\n",
    "print(outlier_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclists_with_outliers = connectivity_approach(df_cyclists_with_outliers)\n",
    "\n",
    "outlier_rows = df_cyclists_with_outliers[df_cyclists_with_outliers[\"connectivity_approach_outlier\"] == True]\n",
    "print(outlier_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc5_'></a>[One-class SVM](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_class_svm(df):\n",
    "    \"\"\"\n",
    "    Detect outliers in a DataFrame using the One-Class SVM approach.\n",
    "\n",
    "    This function applies the One-Class Support Vector Machine (SVM) algorithm to identify outliers in the numeric columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A DataFrame containing the data to be analyzed. Only numeric columns are considered for outlier detection.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with additional columns \"oneclass_svm_degree\" & \"oneclass_svm_outlier\".\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If there are no numeric columns in the DataFrame.\n",
    "    \"\"\"\n",
    "    from sklearn.svm import OneClassSVM\n",
    "\n",
    "    # Select only numeric columns from df\n",
    "    numeric_columns = df.select_dtypes(include=\"number\")\n",
    "    # Drop rows with missing values (NaN) in the selected columns. There shouldn't be any since this set\n",
    "    # of tests runs after the imputations, but we'll keep this in case we want to run it before imputing missing values.\n",
    "    numeric_data = numeric_columns.dropna()\n",
    "\n",
    "    kernel = \"linear\"\n",
    "    algorithm = OneClassSVM(kernel=kernel, nu=0.9)\n",
    "    algorithm.fit(numeric_data)\n",
    "\n",
    "    # Run the prediction: inliers will be +1 for, outliers will be -1\n",
    "    outlier_classification_scores = algorithm.predict(numeric_data)\n",
    "    outlier_distance_scores = algorithm.score_samples(numeric_data)\n",
    "\n",
    "    df.loc[numeric_data.index, \"oneclass_svm_degree\"] = outlier_distance_scores\n",
    "\n",
    "    # Convert the outlier classification scores to a boolean column: True for outliers (-1), False for inliers (1)\n",
    "    outlier_series = pd.Series(False, index=df.index)\n",
    "    outlier_series[numeric_data.index] = (outlier_classification_scores == -1)\n",
    "    df[\"oneclass_svm_outlier\"] = outlier_series\n",
    "\n",
    "    # Plot result\n",
    "    sorted_outlier_degrees = sorted(outlier_distance_scores)\n",
    "    sns.lineplot(\n",
    "        x=range(len(sorted_outlier_degrees)),\n",
    "        y=sorted_outlier_degrees\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_races_with_outliers = one_class_svm(df_races_with_outliers)\n",
    "\n",
    "outlier_rows = df_races_with_outliers[df_races_with_outliers[\"oneclass_svm_outlier\"] == True]\n",
    "print(outlier_rows)\n",
    "\n",
    "# Drop the oneclass_svm_degree column since we don't want it from now on\n",
    "df_races_with_outliers.drop('oneclass_svm_degree', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclists_with_outliers = one_class_svm(df_cyclists_with_outliers)\n",
    "\n",
    "outlier_rows = df_cyclists_with_outliers[df_cyclists_with_outliers[\"oneclass_svm_outlier\"] == True]\n",
    "print(outlier_rows)\n",
    "\n",
    "# Drop the oneclass_svm_degree column since we don't want it from now on\n",
    "df_cyclists_with_outliers.drop('oneclass_svm_degree', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc6_'></a>[Isolation forest](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isolation_forest(df):\n",
    "    \"\"\"\n",
    "    Detect outliers in a DataFrame using the Isolation Forest method.\n",
    "\n",
    "    This function applies the Isolation Forest algorithm to identify outliers in the numeric columns of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): A DataFrame containing the data to be analyzed. Only numeric columns are considered for outlier detection.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The original DataFrame with additional columns: \"isolation_forest_degree\", \"isolation_forest_scores\" & \"isolation_forest_outlier\".\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If there are no numeric columns in the DataFrame.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import seaborn as sns\n",
    "    from sklearn.ensemble import IsolationForest\n",
    "\n",
    "    # Select only numeric columns from df\n",
    "    numeric_columns = df.select_dtypes(include=\"number\")\n",
    "    # Drop rows with missing values (NaN) in the selected columns. There shouldn't be any since this set\n",
    "    # of tests runs after the imputations, but we'll keep this in case we want to run it before imputing missing values.\n",
    "    numeric_data = numeric_columns.dropna()\n",
    "\n",
    "    # Use the number of numeric columns as our max_features\n",
    "    max_features = numeric_data.shape[1]\n",
    "    algorithm = IsolationForest(max_features=max_features)\n",
    "    algorithm.fit(numeric_data)\n",
    "\n",
    "    outlier_degrees = algorithm.decision_function(numeric_data) + 0.5\n",
    "    # Outliers are 1, inliers are 0\n",
    "    outlier_scores = 1 - (algorithm.predict(numeric_data) + 1) / 2\n",
    "\n",
    "    df.loc[numeric_data.index, \"isolation_forest_degree\"] = outlier_degrees\n",
    "    df.loc[numeric_data.index, \"isolation_forest_scores\"] = outlier_scores\n",
    "\n",
    "    outlier_series = pd.Series(False, index=df.index)\n",
    "    outlier_series[numeric_data.index] = (outlier_scores == 1)\n",
    "    df[\"isolation_forest_outlier\"] = outlier_series\n",
    "\n",
    "    # Plot result\n",
    "    sorted_outlier_degrees = sorted(outlier_degrees)\n",
    "    sns.lineplot(\n",
    "        x=range(len(sorted_outlier_degrees)),\n",
    "        y=sorted_outlier_degrees\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_races_with_outliers = isolation_forest(df_races_with_outliers)\n",
    "\n",
    "outlier_rows = df_races_with_outliers[df_races_with_outliers[\"isolation_forest_outlier\"] == True]\n",
    "outlier_rows\n",
    "\n",
    "# Drop the oneclass_svm_degree column since we don't want it from now on\n",
    "df_races_with_outliers.drop('isolation_forest_degree', axis=1, inplace=True)\n",
    "df_races_with_outliers.drop('isolation_forest_scores', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cyclists_with_outliers = isolation_forest(df_cyclists_with_outliers)\n",
    "\n",
    "outlier_rows = df_cyclists_with_outliers[df_cyclists_with_outliers[\"isolation_forest_outlier\"] == True]\n",
    "outlier_rows\n",
    "\n",
    "# Drop the oneclass_svm_degree column since we don't want it from now on\n",
    "df_cyclists_with_outliers.drop('isolation_forest_degree', axis=1, inplace=True)\n",
    "df_cyclists_with_outliers.drop('isolation_forest_scores', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc7_'></a>[Get the final list of 'outlier' columns](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the columns that were added by the outlier tests, we'll drop all the rows we consider \"outliers\". To consider a row as an outlier, we'll assume that we want a majority of tests (3+ out of 5) indicating it as an outlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of 'test result' columns\n",
    "outlier_columns = [\n",
    "    'isolation_forest_outlier', \n",
    "    'oneclass_svm_outlier', \n",
    "    'connectivity_approach_outlier', \n",
    "    'gmm_outlier', \n",
    "    'pca_outlier'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Races"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows where at least 3 out of the 5 specified columns are True (indicating outliers)\n",
    "df_outliers = df_races_with_outliers[df_races_with_outliers[outlier_columns].sum(axis=1) >= 3].drop(columns=outlier_columns)\n",
    "\n",
    "# Select rows where fewer than 3 out of the 5 specified columns are True (indicating non-outliers)\n",
    "df_non_outliers = df_races_with_outliers[df_races_with_outliers[outlier_columns].sum(axis=1) < 3].drop(columns=outlier_columns)\n",
    "\n",
    "# Write the DataFrames to CSV files\n",
    "df_outliers.to_csv('../dataset/df_races_only_outliers.csv', index=False)\n",
    "df_non_outliers.to_csv('../dataset/df_races_no_outliers.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cyclists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select rows where at least 3 out of the 5 specified columns are True (indicating outliers)\n",
    "df_outliers = df_cyclists_with_outliers[df_cyclists_with_outliers[outlier_columns].sum(axis=1) >= 3].drop(columns=outlier_columns)\n",
    "\n",
    "# Select rows where fewer than 3 out of the 5 specified columns are True (indicating non-outliers)\n",
    "df_non_outliers = df_cyclists_with_outliers[df_cyclists_with_outliers[outlier_columns].sum(axis=1) < 3].drop(columns=outlier_columns)\n",
    "\n",
    "# Write the DataFrames to CSV files\n",
    "df_outliers.to_csv('../dataset/df_cyclists_only_outliers.csv', index=False)\n",
    "df_non_outliers.to_csv('../dataset/df_cyclists_no_outliers.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
